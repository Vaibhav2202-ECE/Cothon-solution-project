{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock market forecasting using Time Series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')\n",
    "stock_data = pd.read_csv('../input/price-volume-data-for-all-us-stocks-etfs/Stocks/acgl.us.txt',sep=',', index_col='Date', parse_dates=['Date'], date_parser=dateparse).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the per day closing price of the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#plot close price\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Prices')\n",
    "plt.plot(stock_data['Close'])\n",
    "plt.title('ARCH CAPITAL GROUP closing price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Distribution of the dataset\n",
    "df_close.plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Test for staionarity\n",
    "def test_stationarity(timeseries):\n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(12).mean()\n",
    "    rolstd = timeseries.rolling(12).std()\n",
    "    #Plot rolling statistics:\n",
    "    plt.plot(timeseries, color='blue',label='Original')\n",
    "    plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean and Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    print(\"Results of dickey fuller test\")\n",
    "    adft = adfuller(timeseries,autolag='AIC')\n",
    "    # output for dft will give us without defining what the values are.\n",
    "    #hence we manually write what values does it explains using a for loop\n",
    "    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])\n",
    "    for key,values in adft[4].items():\n",
    "        output['critical value (%s)'%key] =  values\n",
    "    print(output)\n",
    "    \n",
    "test_stationarity(df_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#To separate the trend and the seasonality from a time series, \n",
    "# we can decompose the series using the following code.\n",
    "result = seasonal_decompose(df_close, model='multiplicative', freq = 30)\n",
    "fig = plt.figure()  \n",
    "fig = result.plot()  \n",
    "fig.set_size_inches(16, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by taking a log of the series to reduce the magnitude of the values and reduce the rising trend in the series. Then after getting the log of the series, we find the rolling average of the series. A rolling average is calculated by taking input for the past 12 months and giving a mean consumption value at every point further ahead in series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#if not stationary then eliminate trend\n",
    "#Eliminate trend\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "df_log = np.log(df_close)\n",
    "moving_avg = df_log.rolling(12).mean()\n",
    "std_dev = df_log.rolling(12).std()\n",
    "plt.legend(loc='best')\n",
    "plt.title('Moving Average')\n",
    "plt.plot(std_dev, color =\"black\", label = \"Standard Deviation\")\n",
    "plt.plot(moving_avg, color=\"red\", label = \"Mean\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create an ARIMA model and will train it with the closing price of the stock on the train data. So let us split the data into training and test set and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#split data into train and training set\n",
    "train_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Closing Prices')\n",
    "plt.plot(df_log, 'green', label='Train data')\n",
    "plt.plot(test_data, 'blue', label='Test data')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=3, max_q=3, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "print(model_autoARIMA.summary())\n",
    "model_autoARIMA.plot_diagnostics(figsize=(15,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the Auto ARIMA model provided the value of p,d, and q as 1, 1 and 2 respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Modeling\n",
    "# Build Model\n",
    "model = ARIMA(train_data, order=(1,1,2))  \n",
    "fitted = model.fit(disp=-1)  \n",
    "print(fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's start forecast the stock prices on the test dataset keeping 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = fitted.forecast(321, alpha=0.05)  # 95% conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=test_data.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=test_data.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=test_data.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5), dpi=100)\n",
    "plt.plot(train_data, label='training data')\n",
    "plt.plot(test_data, color = 'blue', label='Actual Stock Price')\n",
    "plt.plot(fc_series, color = 'orange',label='Predicted Stock Price')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.10)\n",
    "plt.title('ARCH CAPITAL GROUP Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('ARCH CAPITAL GROUP Stock Price')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our model did quite handsomely. Let us also check the commonly used accuracy metrics to judge forecast results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# report performance\n",
    "mse = mean_squared_error(test_data, fc)\n",
    "print('MSE: '+str(mse))\n",
    "mae = mean_absolute_error(test_data, fc)\n",
    "print('MAE: '+str(mae))\n",
    "rmse = math.sqrt(mean_squared_error(test_data, fc))\n",
    "print('RMSE: '+str(rmse))\n",
    "mape = np.mean(np.abs(fc - test_data)/np.abs(test_data))\n",
    "print('MAPE: '+str(mape))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4538,
     "sourceId": 7213,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30042,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
